{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "saItxTU2Vs9p"
   },
   "source": [
    "# Deep Learning 2019\n",
    "## Assignment 6 - Attention Mechanism\n",
    "Please complete the questions below by modifying this notebook and send this file via e-mail to\n",
    "\n",
    "__[pir-assignments@l3s.de](mailto:pir-assignments@l3s.de?subject=[DL-2019]%20Assignment%20X%20[Name]%20[Mat.%20No.]&)__\n",
    "\n",
    "using the subject __[DL-2019] Assignment X [Name] [Mat. No.]__. The deadline for this assignment is __June 18th, 2019, 9AM__. Before your submission please replace fields __[Name]__ and __[Mat. No.]__ with your own name and registration number respectively (please keep the brackets), and replace the __X__ in the filename with the number of the current assignment.\n",
    "\n",
    "Programming assignments have to be completed using Python 3. __Please do NOT use Python 2.__\n",
    "\n",
    "__Always explain your answers__ (do not just write 'yes' or 'no')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9Ar0ZUtVs9r"
   },
   "source": [
    "Please add your name and matriculation number below:\n",
    "\n",
    "__Name:__\n",
    "<br>\n",
    "__Mat. No.:__\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZBXUDDeVs-B"
   },
   "source": [
    "### 1. Quick quiz on Attention\n",
    "1. Why do we care about Attention?\n",
    "2. What are differences between hard- vs soft-attention; please also provide pros and cons of both approaches as compared to using Attention.\n",
    "3. What are differences between standard Attention and Transformer?\n",
    "4. Does Transformer use soft- or hard-attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Design Choices for Transformer\n",
    "In the lecture it is briefly mentioned Transformer as pllied for language translation and \n",
    "for images. Based on those we can extend Transformer into following situations:\n",
    "\n",
    "1. First consider Images. Let us assume we have detected objects in the form of bounding boxes with [x,y] coordinates (top-left, bottom-right) and corresponding features (vector of size 2048 for each object). Could you please design Transformer architecture applicable for such an input representation? Please also be precise regarding particular design choices, e.g., which weights are shared, and dimensionality of all the vectors. Please also take into consideration that images may have different number of detected objects whereas the vanilla Transformer assumes a fixed number of these objects.\n",
    "\n",
    "2. Let us work with videos which are sequences of images. Could you design a variant of Transformer applicable for sequences of images? You can choose your favorite input representation: image tensor for each frame, detected objects in each frame, or both. Please focus on representing temporal sequences, comment your design choices, and be precise regarding the design choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Coding exercise\n",
    "Recall that we have implemented a very simple LSTM based sentimental classification model in the 4th assignment. Now it is the time to replace the LSTM module with the Transform one. Again we will use the IMDB dataset and finish binary classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "17473536/17464789 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "['<START>', u'this', u'film', u'was', u'just', u'brilliant', u'casting', '<UNK>', '<UNK>', u'story', u'direction', '<UNK>', u'really', '<UNK>', u'the', u'part', u'they', u'played', u'and', u'you', u'could', u'just', u'imagine', u'being', u'there', u'robert', '<UNK>', u'is', u'an', u'amazing', u'actor', u'and', u'now', u'the', u'same', u'being', u'director', '<UNK>', u'father', u'came', u'from', u'the', u'same', '<UNK>', '<UNK>', u'as', u'myself', u'so', u'i', u'loved', u'the', u'fact', u'there', u'was', u'a', u'real', '<UNK>', u'with', u'this', u'film', u'the', '<UNK>', '<UNK>', u'throughout', u'the', u'film', u'were', u'great', u'it', u'was', u'just', u'brilliant', u'so', u'much', u'that', u'i', '<UNK>', u'the', u'film', u'as', u'soon', u'as', u'it', u'was', u'released', u'for', '<UNK>', u'and', u'would', u'recommend', u'it', u'to', u'everyone', u'to', u'watch', u'and', u'the', '<UNK>', '<UNK>', u'was', u'amazing', u'really', '<UNK>', u'at', u'the', u'end', u'it', u'was', u'so', u'sad', u'and', u'you', u'know', u'what', u'they', u'say', u'if', u'you', '<UNK>', u'at', u'a', u'film', u'it', u'must', u'have', u'been', u'good', u'and', u'this', u'definitely', u'was', u'also', '<UNK>', u'to', u'the', u'two', u'little', '<UNK>', u'that', u'played', u'the', '<UNK>', u'of', '<UNK>', u'and', u'paul', u'they', u'were', u'just', u'brilliant', u'children', u'are', u'often', u'left', u'out', u'of', u'the', '<UNK>', '<UNK>', u'i', u'think', u'because', u'the', u'stars', u'that', u'play', u'them', u'all', '<UNK>', u'up', u'are', u'such', u'a', u'big', '<UNK>', u'for', u'the', u'whole', u'film', u'but', u'these', u'children', u'are', u'amazing', u'and', u'should', u'be', '<UNK>', u'for', u'what', u'they', u'have', u'done', u\"don't\", u'you', u'think', u'the', u'whole', u'story', u'was', u'so', '<UNK>', u'because', u'it', u'was', u'true', u'and', u'was', '<UNK>', u'life', u'after', u'all', u'that', u'was', '<UNK>', u'with', u'us', u'all']\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "num_words = 1000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=num_words, index_from=3)\n",
    "word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "word_to_id = {k: v + 3 for k, v in word_to_id.items()}\n",
    "word_to_id['<PAD>'] = 0\n",
    "word_to_id['<START>'] = 1\n",
    "word_to_id['<UNK>'] = 2\n",
    "id_to_word = {value: key for key, value in word_to_id.items()}\n",
    "\n",
    "def get_text(seq):\n",
    "    return list(map(id_to_word.get, seq))\n",
    "\n",
    "print(x_train[0])\n",
    "print(get_text(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reuse your code for the 4th assignment and replace the LSTM/GRU unit with Transformer architecture. Compare the different requirements of two different models. In order to integrate Transformer to your sentimental classification model, what information is needed additionally as input? \n",
    "Hint 1: you can find the Transformer implementation in [the tensorflow's github page under the `tensor2tensor`repository](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py).\n",
    "Hint 2: This is the colab [link](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb) to a colab python notebook that helps you better understanding the Transformer model\n",
    "\n",
    "2. Visualize the weight matrix of selecting tokens (the self-attention matrix) for a input you like using `tensor2tensor.visualization.attention.show()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solution"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "[DL-2019] Assignment 4 - Recurrent Neural Networks-solution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
