{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 2019\n",
    "## Assignment 2 - Neural Networks and Loss Functions\n",
    "Please complete the questions below by modifying this notebook and send this file via e-mail to\n",
    "\n",
    "__[pir-assignments@l3s.de](mailto:pir-assignments@l3s.de?subject=[DL-2019]%20Assignment%20X%20[Name]%20[Mat.%20No.]&)__\n",
    "\n",
    "using the subject __[DL-2019] Assignment X [Name] [Mat. No.]__. The deadline for this assignment is __May 7th, 2019, 9AM__.\n",
    "\n",
    "Programming assignments have to be completed using Python 3. __Please do not use Python 2.__\n",
    "\n",
    "__Always explain your answers__ (do not just write 'yes' or 'no')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add your name and matriculation number below:\n",
    "\n",
    "__Name:__\n",
    "<br>\n",
    "__Mat. No.:__\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multilayer Perceptron\n",
    "\n",
    "Consider an MLP with $n > 0$ hidden layers $h_1, h_2, ..., h_n$. Let all activation functions in this network be __linear__, i.e. all neurons use the activation function $f(x) = x$. Show that this model is a __linear predictor__, i.e. there exists an equivalent MLP with no hidden layers (only input and output layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Learning XOR\n",
    "The XOR function is defined as\n",
    "\\begin{equation}\n",
    "    x_1 \\oplus x_2 =\n",
    "    \\begin{cases}\n",
    "        0 \\quad x_1 = x_2\\\\\n",
    "        1 \\quad x_1 \\neq x_2\\\\\n",
    "    \\end{cases}.\n",
    "\\end{equation}\n",
    "\n",
    "In this task we want to use `scikit-learn` to train a linear classifier to learn the XOR function.\n",
    "\n",
    "1. What are the possible input-output-pairs $(x, y)$?\n",
    "2. Use `sklearn.linear_model.LinearRegression` to train a linear classifier on all pairs from 1.\n",
    "3. Test your classifier. Is it working well? Why (not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Learning XOR with MLP\n",
    "For this task, __the only library allowed is numpy__. Specifically, do not use a deep learning library.\n",
    "\n",
    "We now want to implement a simple feed-forward net that can learn the XOR function. Our network should have a single $3$-dimensional hidden layer $h$ and use sigmoid activation in all layers.\n",
    "\n",
    "1. What are the dimensions of the two weight matrices?\n",
    "2. Implement the forward pass. Initialize the weight matrices randomly in $[-1; 1]$. You can omit the bias terms in this example.\n",
    "3. Implement the backward pass. Use SGD optimization and $L_2$ (mean squared error) loss. Set the learning rate to $\\eta = 1$.\n",
    "4. Train and test your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feed-forward Network with `scikit-learn`\n",
    "In this problem, we are going to learn how to train a feed-forward neural network with the `sklearn.neural_network` module in `scikit-learn`. We will train an `sklearn.neural_network.MLPClassifier` on the [__Iris dataset__](https://en.wikipedia.org/wiki/Iris_flower_data_set) to classify flowers.\n",
    "\n",
    "1. Load the Iris dataset and split it into 90% for training and 10% for testing using the `train_test_split` function. Then train an `MLPClassifier` with __3 hidden layers__ on the training data after necessary preprocessing. During training, perform validation and enable the `early_stopping` functionality based on validation data by setting `validation_fraction` to $0.1$. Furthermore, the model should use an __L2 penalty__ to avoid overfitting. Evaluate your model on the test data.\n",
    "\n",
    "2. Choose a proper metric and draw the learning curve (`sklearn.model_selection.learning_curve`) of this model using a $5$-fold cross validation split. Compute the variance across different iterations for different sizes of training data. What is the downside of setting aside a single validation set __statically__, like in the first problem, compared with the $5$-fold cross validation method?\n",
    "\n",
    "3. As you might have noticed from the data, the distribution of the label classes is not uniform, which means, while sampling validation data from the whole set, it is possible to sample a set in a different distribution. What kind of problems can this cause? How can you deal with this situation?\n",
    "\n",
    "$^1$ The `MLPClassifier` module is quite limited in terms of customizability. For instance, [custom loss functions are not supported due to performance reasons](https://github.com/scikit-learn/scikit-learn/issues/1701). Starting from the next assignment, we will use actual deep learning libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
