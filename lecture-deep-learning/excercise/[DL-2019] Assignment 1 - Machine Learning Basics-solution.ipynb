{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 2019\n",
    "## Assignment 1 - Machine Learning Basics\n",
    "Please complete the questions below by modifying this notebook and send this file via e-mail to\n",
    "\n",
    "__[pir-assignments@l3s.de](mailto:pir-assignments@l3s.de?subject=[DL-2019]%20Assignment%20X%20[Name]%20[Mat.%20No.]&)__\n",
    "\n",
    "using the subject __[DL-2019] Assignment X [Name] [Mat. No.]__. The deadline for this assignment is __April 30th, 2019, 9AM__.\n",
    "\n",
    "Programming assignments have to be completed using Python 3. __Please do not use Python 2.__\n",
    "\n",
    "__Always explain your answers__ (do not just write 'yes' or 'no')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add your name and matriculation number below:\n",
    "\n",
    "__Name:__\n",
    "<br>\n",
    "__Mat. No.:__\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bias-Variance Tradeoff\n",
    "\n",
    "You have a dataset of $1000$ instances that is divided into a Train-Dev-Test set $(60\\%-20\\%-20\\%)$. The bayes error (or human performance) is $5\\%$. \n",
    "\n",
    "1. If the training error is $1\\%$ and the dev error is $10\\%$, is it a bias or a variance problem?\n",
    "\n",
    "2. If the training error is $10\\%$ and the dev error is $10\\%$, is it a bias or a variance problem?\n",
    "\n",
    "3. If the training error is $10\\%$ and the dev error is $6\\%$, is it a bias or a variance problem?\n",
    "\n",
    "4. If the training set and dev set are differently distributed, what can you expect? \n",
    "\n",
    "5. Is it acceptable to have different dev and test distributions? Why?\n",
    "\n",
    "6. Is it acceptable to have different distribution of training data from dev and test (Dev and test set have the same distribution)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "1. Obtaining training error less than dev error as well as bayes error is a clear case of overfitting to training data. Such a model has low bias and high variance.\n",
    "\n",
    "2. Having equal training and dev error and a lower bayes error indicates the problem of underfitting. In such a case there is high bias (underfitting) and low variance (no change between training and dev error).\n",
    "\n",
    "3. Such a case with training error larger than bayes error but dev error close to bayes error indicates difference between distributions of training and dev sets. A larger difference between training error and dev error indicates high bias (underfitting) and high variance (difference between dev and training error).\n",
    "\n",
    "4. Training and dev error can differ considerably.\n",
    "\n",
    "5. No, because the purpose of setting up the dev set is to depict the ability of generalization of the model during training in advance. Therefore the distributions of dev data (used as kind of a component of training process) and test data (basically corresponds the 'real world') should be similar.\n",
    "\n",
    "6. No. High difference between distributions of training and dev (test) sets can cause both bias and variance problem. After all we don't want to train a data on a way too deviant training set from the real world (dev and test sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dev-Test Splits\n",
    "If your dataset has $10^6$ instances and the bayes error is $5\\%$, \n",
    "1. are dev and test splits of $1\\%$ acceptable, if the bayes error on both dev and test is $5\\%$?\n",
    "2. are dev and test splits of $1\\%$ acceptable, if the bayes error on both dev and test splits is $15\\%$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "1. Yes, because in this case dev and test set are from the same distribution as the training set. In this case the bayes error on the training set will also be $5\\%$.\n",
    "\n",
    "2. No, because the dev and test splits now follow a different distribution. The traing and dev sets have a higher percentage of (bad) examples leading to human error than that in the training set. In this case the bayes error on training set will be $4.79\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sum of Squares Loss\n",
    "Given a polynomial function of the form\n",
    "\\begin{equation} \n",
    "    f(x, {\\bf{w}}) = \\sum_{j=0}^M w_j x^j.\n",
    "\\end{equation}\n",
    "We are given a training set comprising $N$ observations of $x$, given by $x_1, x_2, ..., x_n$, together with the corresponding observations of target values $y_1, y_2, ..., y_n$.\n",
    "\n",
    "We would like to fit the data to the polynomial function, $f(x, {\\bf{w}})$ by minimizing the following loss function:\n",
    "\\begin{equation} \n",
    "    E({\\bf{w}}) = {1 \\over 2}\\sum_{n=1}^N (f(x_n, {\\bf{w}}) - y_n)^2.\n",
    "\\end{equation}\n",
    "Show that the coefficients ${\\bf{w}} = \\{w_i\\}$ that minimize the above loss function are given by the solution to the following set of linear equations:\n",
    "\\begin{equation} \n",
    "    \\sum_{j=0}^M A_{ij} w_j = Y_i\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation} \n",
    "    A_{ij} = \\sum_{n=1}^N (x_n)^{i+j} \\text{ and } Y_i =\\sum_{n=1}^N (x_n)^i y_n.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "Equating the partial derivative of $E({\\bf{w}})$ with respect to each $w_i$ to $0$ we obtain\n",
    "\\begin{equation}\n",
    "    \\sum_{n=1}^N (f(x_n, {\\bf{w}}) - y_n) \\cdot {\\partial f(x_n, {\\bf{w}}) \\over \\partial {w_i}} = 0\\\\\n",
    "    \\implies \\sum_{n=1}^N \\left(\\sum_{j=0}^M w_j (x_n)^j - y_n\\right)(x_n)^i = 0.\n",
    "\\end{equation}\n",
    "Rearranging the terms we obtain\n",
    "\\begin{equation}\n",
    "    \\sum_{j=0}^M \\sum_{n=1}^N (x_n)^{i+j} w_j = \\sum_{n=1}^N (x_n)^i y_n.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear Regression\n",
    "Implement a simple linear regression with __Numpy__ to fit a line, $h(x) = w_1 + w_2 x$,  to a set of points generated using the `generate_data` function as defined below. In particular, find $w_1$ and $w_2$ such that the sum of squares error, $\\sum_i ||h(x_i) - y_i||^2$, is minimized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_data(f, spread, x_start, x_end, delta=1):\n",
    "    \"\"\"Generate a number of data points from f with some spread.\"\"\"\n",
    "    x = np.asarray(np.arange(x_start, x_end, delta))\n",
    "    y = f(x) + (np.random.rand(*x.shape) - 0.5) * spread\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def lin_reg(x, y):\n",
    "    \"\"\"\n",
    "    Return the exact linear regression line, i.e. the weights which minimize the loss.\n",
    "\n",
    "    Input values:\n",
    "        * x = [x_1, ..., x_n]: the x-values of the data points\n",
    "        * y = [y_1, ..., y_n]: the y-values of the data points\n",
    "\n",
    "    Return w = (w_1, w_2) such that w_1 is the bias and w_2 is the slope, i.e. h(x) = w_1 + w_2 * x.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return 0, 0\n",
    "\n",
    "\n",
    "# generate some points\n",
    "f = lambda x: 2 + 3 * x\n",
    "x, y = generate_data(f, spread=5, x_start=0, x_end=10, delta=0.05)\n",
    "\n",
    "# plot the points\n",
    "pyplot.plot(x, y, marker='.', linewidth=0)\n",
    "\n",
    "# plot f\n",
    "pyplot.plot(x, f(x), linewidth=3)\n",
    "\n",
    "# perform linear regression\n",
    "w = lin_reg(x, y)\n",
    "\n",
    "# plot the regression line\n",
    "pyplot.plot(x, w[0] + w[1] * x, linewidth=3)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_data(f, spread, x_start, x_end, delta=1):\n",
    "    \"\"\"Generate a number of data points from f with some spread.\"\"\"\n",
    "    x = np.asarray(np.arange(x_start, x_end, delta))\n",
    "    y = f(x) + (np.random.rand(*x.shape) - 0.5) * spread\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def lin_reg(x, y):\n",
    "    \"\"\"\n",
    "    Return the exact linear regression line, i.e. the weights which minimize the loss.\n",
    "\n",
    "    Input values:\n",
    "        * x = [x_1, ..., x_n]: the x-values of the data points\n",
    "        * y = [y_1, ..., y_n]: the y-values of the data points\n",
    "\n",
    "    Return w = (w_1, w_2) such that w_1 is the bias and w_2 is the slope, i.e. h(x) = w_1 + w_2 * x.\n",
    "    \"\"\"\n",
    "    # change the shape of x from (n,) to (n, 2), where n is the number of points\n",
    "    X = np.expand_dims(x, axis=1)\n",
    "    ones = np.full_like(X, 1)\n",
    "    X = np.append(ones, X, axis=1)\n",
    "    # X is now of the form [[1, x_1], ..., [1, x_n]]\n",
    "    w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return w\n",
    "    \n",
    "\n",
    "# generate some points\n",
    "f = lambda x: 2 + 3 * x\n",
    "x, y = generate_data(f, spread=5, x_start=0, x_end=10, delta=0.05)\n",
    "\n",
    "# plot the points\n",
    "pyplot.plot(x, y, marker='.', linewidth=0)\n",
    "\n",
    "# plot f\n",
    "pyplot.plot(x, f(x), linewidth=3)\n",
    "\n",
    "# perform linear regression\n",
    "w = lin_reg(x, y)\n",
    "\n",
    "# plot the regression line\n",
    "pyplot.plot(x, w[0] + w[1] * x, linewidth=3)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "Suppose we have a stochastic system in which events of interest occur independently with small and constant probability, i.e., the events are independently and identically distributed (i.i.d.). Such a process is called a Poisson process. \n",
    "\n",
    "The time intervals or delays between individual events in a Poisson process follow an exponential distribution with parameter $\\lambda$ as follows \n",
    "\n",
    "\\begin{equation}\n",
    "\\Pr(x)=\\begin{cases}\n",
    "  \\lambda e^{-\\lambda x} & x \\geq 0\\\\\n",
    "  0 & x<0\n",
    "\\end{cases},\n",
    "\\end{equation}\n",
    "\n",
    "Now, let $\\{x_i\\} = \\{x_1, x_2, . . . , x_n\\}$ denote our observed time interval data. \n",
    "\n",
    "1. What is the log likelihood of this data under the exponential model $\\Pr(x)$?\n",
    "\n",
    "2. Derive an analytical form for $\\lambda$ which maximizes the likelihood of our observed data.\n",
    "\n",
    "3. Implement the maximum likehood estimator, i.e. compute $\\lambda$ for the following observed time intervals.\n",
    "\n",
    "\n",
    "$$\\{x_1, x_2, ..., x_n\\} = \\{0.08817335, 0.7699288, 1.37257133, 1.07451531, 0.02959294, 0.16400137, 0.12498293, 0.56801231, 0.23876629, 0.80438577\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_mle(data):\n",
    "    \"\"\"\n",
    "    This function estimate the parameter lambda of the exponential\n",
    "    distribution from the input data using maximum likelihood \n",
    "    estimation (MLE). The PDF of the distribution is defined as:\n",
    "    \n",
    "    f(x; lambda) = lambda * exp(-lambda * x) if x >= 0 else 0\n",
    "    \n",
    "    Parameter\n",
    "    ---\n",
    "    data: array-like input data, indicating the time intervals between\n",
    "          events\n",
    "          \n",
    "    Returns\n",
    "    ---\n",
    "    lambda: the parameter estimated using MLE\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    return 0\n",
    "\n",
    "\n",
    "intervals = [0.08817335, 0.7699288 , 1.37257133, 1.07451531, 0.02959294,\n",
    "             0.16400137, 0.12498293, 0.56801231, 0.23876629, 0.80438577]\n",
    "print(\"{:0.4f}\".format(exponential_mle(intervals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "$$\n",
    "\\mathcal{L}(X; \\lambda) = \\log \\prod_{i=1}^n\\Pr(x_i) = \\sum_{i=1}^n\\log \\lambda e^{-\\lambda x_i} = n\\log\\lambda - \\lambda\\sum_{i=1}^n x_i $$\n",
    "2. In order to find the value of $\\lambda$ which maximizes $\\mathcal{L}$ we compute its derivative with respect to $\\lambda$ and set it to $0$,\n",
    "$$\n",
    "\\frac{\\partial}{\\partial\\lambda}\\mathcal{L}(x_i; \\lambda) = \\frac{n}{\\lambda}-\\sum_{i=1}^n x_i\n",
    "$$\n",
    "and obtain $\\hat\\lambda = {n\\over \\sum_{i=1}^n x_i} .$\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def exponential_mle(data):\n",
    "    \"\"\"\n",
    "    This function estimate the parameter lambda of the exponential\n",
    "    distribution from the input data using maximum likelihood \n",
    "    estimation (MLE). The CDF of the distribution is defined as:\n",
    "    \n",
    "    f(x; lambda) = lambda * exp(-lambda * x) if x >= 0 else 0\n",
    "    \n",
    "    Parameter\n",
    "    ---\n",
    "    data: array-like input data, indicating the time intervals between\n",
    "          events\n",
    "          \n",
    "    Returns\n",
    "    ---\n",
    "    lambda: the parameter estimated using MLE\n",
    "    \"\"\"\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "    return len(data) / sum(data)\n",
    "\n",
    "\n",
    "intervals = [0.08817335, 0.7699288 , 1.37257133, 1.07451531, 0.02959294,\n",
    "             0.16400137, 0.12498293, 0.56801231, 0.23876629, 0.80438577]\n",
    "print(\"{:0.4f}\".format(exponential_mle(intervals)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
